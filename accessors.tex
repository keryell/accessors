\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{a4wide}
\usepackage{url}
\usepackage{listings}
\lstset{language=C++,basicstyle=\small\ttfamily}

% Limit line overflow
\sloppy

\title{Accessors\\
  ---\\
  a C++ standard library class to qualify data accesses}

\author{Ronan Keryell (Xilinx)
  \and Joël Falcou (NumScale)}

\begin{document}

\maketitle

\begin{tabular}{|r|l|}
  \hline
  \textbf{Document} & P0367R0\\\hline
  \textbf{Date} & 2016-05-29\\\hline
  \textbf{Project} & ISO/IEC JTC1 SC22 WG21 Programming Language C++\\\hline
  \textbf{Audience} & SG14, SG1, LEWG\\\hline
  \textbf{Authors} &  Ronan Keryell (Xilinx), Joël Falcou (NumScale)\\\hline
  \textbf{E-mails} & \texttt{ronan.keryell at xilinx dot com}\\
                   & \texttt{joel.falcou at numscale dot com}\\\hline
  \textbf{Reply to} & \texttt{ronan.keryell at xilinx dot com}\\\hline
\end{tabular}


\begin{abstract}
  Accessing data is the most important aspect when it comes to
  high-performance computing or power efficiency in embedded
  computing.

  We propose to abstract data accesses through an \emph{accessor}
  class to give control to the programmer on how fine grain access is
  done, such as caching, memory burst or remote access in
  heterogeneous computing.

  The \lstinline|std::accessor<>| class is a proxy wrapper that
  behaves like the wrapped object but adds access properties to it or
  change the access behaviour.

  For example if you have a slow I/O or a memory access (a special
  case of slow I/O nowadays...) but you know that pretty often the
  result is 42 for obvious reasons, you may rewrite your code
  \begin{lstlisting}
    auto result = f(some_io());
  \end{lstlisting}
  to
  \begin{lstlisting}
    auto result = f(make_accessor<likely> { some_io(), 42 });
  \end{lstlisting}
  and the compiler can decide for example to clone the execution of
  \lstinline|f| to compute ahead \lstinline|f(42)| or even to
  \lstinline|constexpr|-evaluate it and the result is only committed
  when \lstinline|some_io()| comes back and the value is verified as
  predicted. If not, the normal evaluation of \lstinline|f()| goes on.
\end{abstract}


\clearpage

\tableofcontents


\section{Motivation}
\label{sec:motivation}

Demand for high-performance and power efficiency makes architectural
considerations more and more important when programming, specially with
the generalization of distributed computing and heterogeneous
computing involving accelerators, DSP, GPU, FPGA, network
accelerators, etc.

Unfortunately, as for a sequential program running on a CPU, there is
no performance portability when it is about reaching the maximum
performance and power efficiency on a given architecture. Some
execution parameters may have to be tweaked and/or the architecture of the
software has to be deeply changed accordingly. Since there are more
parameters under control in an heterogeneous platform compared to a
CPU, the exploration space is quite wider. Dealing with
this in an automatic way is an intractable issue in the general case but
at least we should have some ways to express some of these details at
the C++ level to reach maximum performance and power efficiency.

For example, currently there is no way to specify how the data are
accessed and if we consider that now most of the energy consumption is
spent in data transfer, specially with external memory, this is
something to address.

Keeping data on a first-level cache in CPU is crucial and it is
important to express which data will benefit or not from being in the
cache. Since cache memories are very small and expensive, specifying
that some data do not take advantage of the cache leaves more room for
data in the critical path.

In the following we develop the concept of \emph{accessor} represented
as a plain C++ class to express how data are accessed in a C++
program.

An accessor is a proxy object that behaves like the object it
represents but with some ways to change the behaviour when read or
written.

Most of the behaviour could be done by language extensions or
\lstinline|#pragma|, but the advantage of having it as a class is that
it can often be implemented in user-mode C++ for simplicity,
portability or debug, and also implemented by a compiler in a
target-specific optimized way on some architectures.

Having a plain object to control accesses provides handy RAII
framework to hide actions in the accessor constructor and destructor,
such as setting up the communication framework or switching on and off
the power of the system that gives access to the object.

Having access properties encoded in the type itself allows propagation
though generic templated function calls or lambda captures and allows
code specialization with metaprogramming according to some access
properties.


\section{Related work}
\label{sec:related-work}

In current C++ standard and proposals or other libraries, some
architectural aspects can already or will be addressed:
\begin{description}
\item[\texttt{thread}] can be used to execute some code in parallel
  on multiple execution units;
\item[\texttt{allocator}] controls the way allocation happens and how
  pointers behave, and thus hide some hardware detail for data access;
\item[constructors and destructors] can hide some architectural details
  and semantics;
\item[operator overloading] is useful to hide some hardware
  operations
  \begin{description}
  \item[\texttt{auto} operator overloading] would make cleaner
    implementation of proxy to some hardware details and cleaning up
    expression templates;
  \item[operator dot overloading] \cite{C++:P00252R0:dot_operator}
    allows changing the behaviour and some extensions to generate
    function objects \cite{C++:P0060R0:function_operator_dot} allow
    interesting use case to change the object behaviour;
  \end{description}
\item[fixed-point] type proposals are useful to have better
  performance on DSP and FPGA;
\item[the concept of view] has some similarities but is more focused
  on some kind of objects, such as \lstinline|array_view| for arrays,
  \lstinline|string_view| for strings, or \lstinline|span| to view a
  sequence as a range:
  \begin{description}
  \item[array\_ref] \cite{C++:P0009R1:array_ref} is a proxy object to
    view some array-like objects in various ways;
  \end{description}
\item[SYCL] is a C++ OpenCL standard from Khronos to execute some
  functors on some accelerators with possibly different address
  spaces, with the concept of accessors representing remote access to
  multidimensional arrays \cite{C++:P00236R0:SYCL};
\item[C++AMP and hcc] \cite{C++:P0069R0:hcc} are C++ extension to
  execute some functors on some accelerators with possibly different
  address spaces, with the concept of \lstinline|array_view|
  representing remote access to multidimensional arrays;

\item non-temporal accessor in Boost.SIMD;

\item[ISO/IEC TR 18037] in the C world, ``Information Technology ---
  Programming languages -- C -- Extensions to support embedded
  processors'' (ISO/IEC JTC1 SC22 WG14 N1169, 2006-04-04
  \url{http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1169.pdf})
  introduces concepts such as the \emph{named address spaces} to
  represent special kinds of memories, that went recycled into CUDA
  and OpenCL address spaces, or named registers and special I/O.
\end{description}

The concept of accessor discussed here is more focused on the action
of reading or writing than on the kind of object.


\section{Accessor}
\label{sec:accessor}

An \lstinline|std::accessor<T, access_kind...>| is a variadic
templated class that act as a proxy object to qualify how an original
\lstinline|T| object is accessed.

Since there are a lot of different ways to access an object, we prefer
to have the accessor to be parametrized by the kind of accessor
instead of having completely different explicit accessor classes:
\begin{lstlisting}
auto io = get_some_memory_mapped_io();
std::accessor<write> use_it { io };
// Now we are sure this is a write-only usage
some_random_code(use_it);
\end{lstlisting}
with the type of the data accessed actually inferred from the
constructor.

Accessors actually compose to define more complex access modes from
basic ones, such as:
\begin{lstlisting}
unsigned char buffer[N];
// Combine a write-only accessor with a modulo accessor to have a
// write-only circular buffer
std::accessor<std::accessor<modulo>, write> wcb { buffer };
generate_some_data(wcb);
\end{lstlisting}
The order of composition matters to match the requested semantics.

Of course the syntax becomes cumbersome and this is why the accessor
is actually a variadic templated class so the previous example can be
simplified as
\begin{lstlisting}
unsigned char buffer[N];
// Combine a write-only accessor with a modulo accessor to have a
// write-only circular buffer
std::accessor<write, modulo> wcb { buffer };
generate_some_data(wcb);
\end{lstlisting}
with the accessor types combined from left to write in the order
mathematical function composition: \emph{make a write accessor on top
  of (from) a modulo accessor.} If some constructor arguments are
required by the accessor there are matched in the reverse order.

A variadic templated factory method is also provided and usable as:
\begin{lstlisting}
double a[10000];
auto p = std::make_accessor<prefetch<16>> { a };
// Use p as a but prefetch from memory 16 elements ahead
f(p);
\end{lstlisting}


\subsection{Non unified memory}
\label{sec:non-unified-memory}

The current C++ memory model assumes more or less that the memory
address space is uniform. Unfortunately, for HPC class machines from
the Top 500 or for embedded systems, this simple addressing scheme
does not hold and there are for example some private memory attached
to each processor or device that cannot be addressed directly by
another processor or device.

The motivation for this \lstinline|accessor| proposal actually comes
from OpenCL SYCL C++ where some functors are remotely executed but need
to interact with a global memory. This is also the concept behind PGAS
(Partitioned Global Address Space) languages or libraries, such as
Coarray C++ or UPC++, where the memory is physically distributed but
can be remotely accessed with some explicit language or library
support instead of transparent virtual shared memory.

The use of a (SYCL) accessor can be seen on this SYCL C++ example:
\begin{lstlisting}
// Create a 1D buffer of N double
cl::sycl::buffer<double, 1> b { N };
// [...]
// Launch on default accelerator:
cl::sycl::queue {}.submit([&](handler &cgh) {
  /* Get an accessor to write the data remotely from inside lambda
     which is off-loaded to the accelerator */
  auto acc = b.get_access<access::write>(cgh);
  // A DIY parallel equivalent of std::iota as a kernel named "init"
  cgh.parallel_for<class init>(N, [=] (auto index) {
                                acc[index] = index;
                               });
  });
\end{lstlisting}

could be generalized in a framework returning a remote accessor to
allow remote access as:
\begin{lstlisting}
std::array<double, N> local;
accessor<remote, write, std::array<double, N>> remote =
  get_some_runtime_remote(local);

std::copy(std::begin(local), std::end(local), std::begin(remote));
\end{lstlisting}

Typical environments usable with this could be SHMEM, Portal4, SYCL,
Coarray C++, RDMA, iWARP, MPI...

Actually the real power from remote accessors would come from the
combination with the \lstinline|array_ref|
\cite{C++:P0009R1:array_ref} to have a simple implementation of the
higher-level accessors found in SYCL or Coarray C++, or implement some
for the other environments.


\subsection{Read/write qualifiers}
\label{sec:readwrite-qualifiers}

In C++ there is the \lstinline|const| qualifier to specify read-only
but there is no way to specify other access modes that normally do not
change the semantics but are useful to increase performance or lower
power consumption.

Here is a list of accessor types:
\begin{description}
\item[\texttt{write}] to access to a write-only data. This avoids for
  example to load or prefetch the cache from memory before writing;
\item[\texttt{read}] to prevent writing back data;
\item[\texttt{read\_write}] normal access by symmetry;
\item[\texttt{discard\_read}] to read data if they are written first
  and do not read the initial value at accessor creation. A typical
  use case is a data locally generated that can be read back locally;
\item[\texttt{discard\_write}] to write data to be locally read but
  won't be written back at accessor destruction;
\item[\texttt{noaccess}] by symmetry, typically to detect
  inappropriate behaviours in a program.
\end{description}


\subsection{Non temporal access}
\label{sec:non-temporal-access}

A \lstinline|non_temporal| accessor allows to access data that won't
be accessed again and typically will not for example use a cache. This
diminish cache transactions and leave the cache for some more useful
usage.

For example when generating a huge amount of data to an array, everything else
would be evicted from the cache without any chance to read the array
back from the cache anyway.

A use case:
\begin{lstlisting}
// An array of 1 TB
double a[2<<37];
auto ac = make_accessor<non_temporal,write>(a);
// Initialize a starting from the end with increasing
// integer starting at 42
std::iota(std::par_vec, ac.rbegin(), ac.rend(), 42);
\end{lstlisting}%>>


\subsection{Aliasing}
\label{sec:aliasing}

Aliasing between different data structures may prevent the compiler
from doing aggressive optimizations. Some proposals exist using
generalize attributes \cite{C++:N3988:aliasing} but it can also be
done with accessors such as:
\begin{lstlisting}
double a[N], b[N];
// Dummy class declarations to be used as alias set tags
class ta;
class tb;

auto ca = make_accessor<alias_tag<ta>>(build_complex_data_structure(a));
auto cb = make_accessor<alias_tag<tb>>(build_complex_data_structure(b));
auto oa = make_accessor<alias_tag<ta>>(other_complex_data_structure(a));
auto ob = make_accessor<alias_tag<tb>>(other_complex_data_structure(b));
// No aliasing
correlation(ca, cb);
correlation(oa, ob);
// Aliasing
correlation(ca, oa);
correlation(cb, ob);
\end{lstlisting}

Inside \lstinline|correlation()| the compiler can use the aliasing
information to optimize more or less the code, as with generalized
attributes from \cite{C++:N3988:aliasing}, but with a type as a tag.

But since it is an accessor class, the programmer can query the
accessor aliasing status with a type trait (\S~\ref{sec:type-traits})
to know if there are aliasing between accessors and if so statically
dispatch completely different algorithms.


\subsection{Sequential access}
\label{sec:sequential-access}

In some case the programmer knows that accesses to an array are
strictly sequential but the compiler cannot prove it. By explicitly
specifying it, a compiler can generate vector memory access or do some
parallel loop nest pipelining where the memory access is completely
replaced for example by a hardware FIFO between execution units.

In the program
\begin{lstlisting}
{
  std::accessor<accessor::sequential,
                accessor::discard_read,
                accessor::discard_write> a { some_array };
  for (int i; i = 0; i != N; ++i)
    a[i] = i;
  for (int i; i = 0; i != N; ++i)
    b[i] = a[i]*2;
}
\end{lstlisting}
the compiler could decide to fuse the 2 loops or to generate 2 Kahn's
processes, 1 producer and 1 consumer, with only an efficient hardware
FIFO in between and eluding the memory transfer on \lstinline|a[i]|.


\subsection{Prefetching}
\label{sec:prefetching}

Latency is often a performance killer and if we know in advance that
we will read some array elements, we could prefetch it. Note that
prefetching is actually independent from caching, so it can be
combined with non temporal access.

\begin{lstlisting}
int a[N];
// Instruct the memory prefetcher to look 16 elements ahead
std::accessor<prefetch<16>> a_p { a };
std::fill(std::begin(a_p), std::end(a_p), 0);
\end{lstlisting}


\subsection{Burst mode}
\label{sec:burst-mode}

Most of the memory interfaces work better when memory transfers are
made with a coarse granularity. It can be specified with this accessor.

Note that since burst mode uses bulk transfer mode, it is not
interesting for example when transferring small data randomly
placed. In this case a burst-size of 1 with a non temporal accessor
can be used.

\begin{lstlisting}
int a[N*20];
// Instruct the memory prefetcher to use a burst mode of 20 elements
std::accessor<burst<20>> a_p { a };

// To generate random integer between 0 and N - 1
std::default_random_engine r;
std::uniform_int_distribution<int> d { 0, N - 1 };
for (int i = 0; i != N; ++i) {
  // Randomly write blocks of 20 elements
  p = std::begin(a_p) + 20*d(r);
  std::fill(p, p + 20, 0);
}
\end{lstlisting}


\subsection{Pipelined access}
\label{sec:pipelined-access}

Software loop pipelining is a classical loop transformation to reduce
intra-iteration dependency by rewriting
\begin{lstlisting}
for (int i = 0; i < N; ++i)
  a[i] = f(b[i]);
\end{lstlisting}
to (assuming $N > 1$):
\begin{lstlisting}
// Prelude
auto r = b[0];
auto w = f(r);
r = b[1];
// Pipelined loop
for (int i = 0; i < N - 2; ++i) {
  a[i] = w;
  w = f(r); // For i + 1
  r = b[i + 2];
}
// Postlude
a[N - 2] = w;
a[N - 1] = f(r);
\end{lstlisting}
which has tremendous effect on low-end processors (micro-controller
with no cache) or FPGA.

A compiler is expected to do this kind of transformations
automatically but some times cannot figure out automatically if it is
legal or what is the actual benefit, for example when iterating on
some complex iterators. By using an \lstinline|accessor<pipelinable>|
compiler can generate a pipelined loop:
\begin{lstlisting}
auto f = [](auto input, auto output) {
  std::transform(std::cbegin(input), std::cend(input),
                   std::begin(output), func);
};

int in[N], out[N];

// Call a pipelined implementation of f without requiring
// interprocedural analysis of func
f(std::make_accessor<pipelinable> { in },
  std::make_accessor<pipelinable> { out });
\end{lstlisting}


\subsection{DMA}
\label{sec:dma}

To take advantage from DMA to transfer data, the transfer can be
encoded as a DMA operation with a DMA accessor.

\begin{lstlisting}
int far_far_away[N];
{
  int near_and_fast[N];
  auto make_accessor<dma> { far_far_away, near_and_fast };
  std::generate(p, p + 20, 0);
}
\end{lstlisting}

The read/write accessor mode can be used to remove useless copy in the
constructor or the destructor.

More complex data transfers may be defined using static DMA
descriptors (can be synthesized in hardware on FPGA) or dynamic DMA
descriptors given in the accessor constructor.

% Add a split constructor or use futures to deal with asynchronous
% DMA?


% \subsection{Memory protection}
% \label{sec:memory-protection}

% Out-of-bound memory access is evil and root of many security
% issues. Systematic bound checking is costly but some architectures
% provides this for free so it is interesting to express with a specific
% accessor:
% \begin{lstlisting}
% char a[N];
% // Use a bound-checker accessor to protect from deprecated insecure
% // function
% std::accessor<bound_check> a_s { a, 20 };
% // Use a dangerous function but throw in case of out-of-bound access
% gets(a_s);
% }
% \end{lstlisting}

% TODO \textbf{Difficult to have this working}
% %% Already addressed by P0122R1 span


\subsection{Bus type}
\label{sec:bus-type}

Some systems allow different types of buses an a variable may be
addressed through these different buses with an accessor specifying a
bus identifier. The concept is standard but the bus identifiers,
besides the default one, are implementation specific:
\begin{lstlisting}
char a;
float b;
std::accessor<bus<axi4>> a_a { a };
std::accessor<bus<axi4>> b_a { b };
std::accessor<bus<main> a_m { a };
std::accessor<bus<main> b_m { b };
// Use different buses in parallel to improve bandwidth
auto sum = a_a + b_m;
auto prod = a_m + b_a;
\end{lstlisting}

The synchronization constraints between the various buses are
implementation dependent.


\subsection{Access width}
\label{sec:access-width}

Embedded systems allow to specify the size of the data-packets
transferred on a bus. This can be specified with:
\begin{lstlisting}
double d;
// Transfer 8-bit at a time
std::accessor<bit_width<8>> d_b { d };
auto a = d_b;
\end{lstlisting}


\subsection{Address mode}
\label{sec:address-mode}

Some architectures allow different addressing modes with different
trade-off, such as PC-relative, based on a base pointer, near to some
page, etc. To compile efficiently with this mode, a specific accessor
is provided.

The available modes are implementation dependent, besides the
\lstinline|std::accessor<address_mode<normal>>|.


% \subsection{Affinity}
% \label{sec:affinity}


\subsection{Translation}
\label{sec:translation}

In embedded systems, it is common to have some level of shared memory
but mapped physically at different addresses. If there is no virtual
memory in use in some part of a system, the address in the different
point-of-views appear as translated by an offset.
\begin{lstlisting}
unsigned char frame_buffer[N];
size_t offset = &display - frame_buffer;
// The screen memory on the display controller
std::accessor<translate> b { frame_buffer, offset };
\end{lstlisting}


\subsection{Modulo addressing}
\label{sec:modulo-addressing}

Implementing some circular buffers may require some kind of modulo
addressing and some processors have this addressing mode. Since it is
impossible to detect automatically this feature in the compiler in the
general case, it should be expressed with an accessor:
\begin{lstlisting}
unsigned char buffer[N];
// b is a kind of infinite array, but with only buffer storage repeated
std::accessor<modulo> b { buffer };
\end{lstlisting}
A specialized version of \cite{C++:P0059R1:ring} could use this
accessor.


\subsection{Address bit setting}
\label{sec:address-bit-setting}

Some architectures encode in the address bus some semantics which is
not used as the part of the address itself, such as supervisor mode,
non executable mode, etc.

A bit-setting accessor allows to change the address bit accordingly
during read or write operations:
\begin{lstlisting}
int a[N];
a[0] = 2;
// On the target architecture, the address space is duplicated on the
// half upper 32KB space for a cacheless access
std::accessor<bit_set<or<(1 << 15)>>> cacheless_access { a };
// as a[123] but do not use the cache
cacheless_access[123] = 4;
\end{lstlisting}



\subsection{Transactional memory}
\label{sec:transactional-memory}

A transactional-memory accessor start a transaction at the accessor
creation up to its destruction, with some transaction behaviour for
the threads using this accessor. In case of write data-race, only one
of the conflicting threads are not rolled back up to the construction
of the accessor.

For example the 2 following functions
\begin{lstlisting}
int shared_data[N];

void f() {
  std::accessor<transaction> a { shared_data };
  foo(a);
}

void g() {
  std::accessor<transaction> b { shared_data };
  bar(b);
}
\end{lstlisting}
may be executed from 2 different threads and will use a transactional
memory behaviour if available, or otherwise the implementation will
fallback on a lock-based solution.


\subsection{Prediction}
\label{sec:prediction}

Sometime the programmer knows some probabilities about the
distribution of values and this can be useful for probabilistic
optimization. For example in
\begin{lstlisting}
int v = some_io();
// Execute f() ahead knowing that most of the time v is 0
std::accessor<likely> prediction { v, 0 };
auto result = f(prediction);
\end{lstlisting}
the compiler can decide for example to clone the execution of
\texttt{f} with some predication to remove side effects while doing a
speculative execution. The actual \texttt{result} will be really
committed only when \texttt{v} come out from the network and is
compared to the predicted value.


We can have a PGO (Profile-Guided Optimization) version of it to
instruct the compiler to instrument the code to do some statistical
analysis of the most common value:
\begin{lstlisting}
// Execute f() ahead after some PGO analysis to figure out common values
auto result = f(make_accessor<pgo_likely> { some_io() });
\end{lstlisting}

We can allow several likely values too.


\subsection{Generic proxy}
\label{sec:generic-proxy}

A proxy accessor delegates all the read and write operations to some
user-provided functors.

It is useful for example for:
\begin{itemize}
\item virtualizing some non existant memory or hardware;
\item implementing transactional memory in user mode;
\item testing with some non existing software part by interacting with
  a mock-up hidden behind an accessor;
\item override the memory operation to do fault injection for
  fault-tolerance evaluation;
\item security testing with fuzzing of inputs.
\end{itemize}


\section{Type traits}
\label{sec:type-traits}

Having classes to qualify accesses makes possible some metaprogramming
according to these type properties.

For this there are some type traits to introspect accessors at compile
time, in the form of
\texttt{std::is\_accessor<\emph{property\_list}>(acc)} or
\texttt{std::get\_accessor<\emph{property\_list}>(acc)}.

For example it is possible to test if 2 accessor types are aliasing or
not:
\begin{lstlisting}
auto correlation = [](auto data1, auto data2) {
  if constexpr (std::is_accessor_v<aliasing_with>(data1, data2))
    slow_conservative_correlation(data1, data2);
  else
    crazy_aggressive_correlation(data1, data2);
};
\end{lstlisting}
to go back to the example from \S~\ref{sec:aliasing}.


\section{Implicit accessor}
\label{sec:implicit-accessor}

Having to use explicit \texttt{accessor} objects may be painfully
intrusive and it would be nice to have something lighter. Of course,
since omnipotent abstract interpretation of a program is impossible,
some kind of program transformation is required by the programmer to
express properties of memory access.

We can use language extensions, \lstinline|#pragma| or generalized
attributes. Language extensions are bad for portability and
acceptance. \lstinline|#pragma| do not compose well with
meta-programming. So we focus here on decorating objects with
accessors.

\begin{lstlisting}
// An array of 1 TB
double a[2<<37] [[std::accessor<non_temporal,sequential>]];

// An implicit accessor is wrapped around all uses of a
std::iota(a.begin(), a.end(), 0);
\end{lstlisting}

But also on any scope, such as class, block, namespace... as for
example to add a behaviour of a transactional memory on all a class:
\begin{lstlisting}
template <typename T>
class message_queue [[std::accessor<transaction>]] {
  T read() {...}

  void write(T &&t) {...}
}
\end{lstlisting}


\section{Implementation ideas}
\label{sec:implementation-ideas}

The implementation basics for the proxy objects are:
\begin{itemize}
\item for fundamental types, have an implicit conversion operator to
  the reference to the fundamental types so the accessor can behave
  like the fundamental type;
\item for object types, the proxy would publicly inherit from the type to
  forward all member access to it;
\item the concept of accessor can just inherits from a reference
  accessor class implementing the proxy behaviour according to the
  basic type (fundamental, array, class, pointer);
\item each kind of accessor inherits from another accessor class and
  adds its own properties to it as member types and optional member
  variables and methods, so at the end a full accessor is an
  aggregation as an inheritance 
\end{itemize}

WIP:
\begin{lstlisting}
template <typename T> struct accessor : {
  typename g
}

struct
  std::accessor<accessor::sequential,
                accessor::discard_read,
                accessor::discard_write> a { some_array };

\end{lstlisting}


\section{Issues}
\label{sec:issues}

Having some objects appearing at other addresses may put some
restriction on the type (such as ``trivially copyable'', ``standard
layout''...).


\section{Conclusion}
\label{sec:conclusion}

Since accessing data is a real issue today for performance and power
efficiency reasons, we introduce the concept of accessor to give the
programmer some ways to optimize data accesses or extend data accesses
beyond Von Neuman's architecture, the natural scope of C/C++,
involving distributed memory and heterogeneous architectures.

We propose to control various aspects such as simple as read/write
access control down to hardware bus selection, cache control,
pipelining, etc.

Instead of extending the language, we propose to encapsulate accesses
in normal STL classes, the \lstinline|std::accessor|, to wrap up
objects and add properties to their accesses. This class is templated
to encode various properties that compose nicely.

Having this information available in the type system allows
introspection and metaprogramming at compile time with specialization
according to the types of possible data accesses.

Combined with concepts such as executors and ranges, it allows
building very-high level parallel distributed applications with very
extreme low-level bare-metal optimizations.


\section*{Acknowledgements}
\label{sec:acknowledgements}

We want to thank all the people from the Khronos OpenCL SYCL committee
for the fruitful discussions leading to this generalization of the
concept of accessor.

Acknowledgments go to Xilinx for supporting this work and also to
colleagues for their fruitful discussions on advanced C++ for FPGA:
specially Ralph Wittig, Jeff Fifield and Sam Bayliss.

Thanks to Lee Howes for his PhD \cite{PhD:Howes2010} research on some
concepts close to accessors and for the discussions on SYCL accessors.

Thanks to Michael Wong for helping bootstrapping this proposal in the
C++ SG14 committee.

The PIPS team from MINES ParisTech and the Par4All team at SILKAN are
thanked for the feedback on compilers using polyhedral techniques for
automatic parallelization got heterogeneous computing and how we could
have ``array regions'' (polyhedral approximations of accesses) in
accessors, even it did not get trough this proposal yet.

Thanks to Albert Cohen for the discussion on how we could have the
PENCIL IR \cite{PENCIL} into C++, even it did not get trough this
proposal yet.


% http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/
\bibliography{accessors}
\bibliographystyle{alpha}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
