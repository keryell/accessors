\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{a4wide}
\usepackage{url}
\usepackage{listings}
\lstset{language=C++,basicstyle=\small\ttfamily}

\title{Accessors\\
  ---\\
  C++ library class to qualify data access\\
  ---\\
  Version 0.2\\
  C++ draft proposal}

\author{Ronan Keryell (Xilinx, \texttt{ronan.keryell at xilinx dot com})
  \and Lee Howes (Facebook, \texttt{xrikcus at gmail dot com})}

\begin{document}

\maketitle

\begin{abstract}
  Accessing data is the most important aspect when it comes to
  high-performance computing or power efficiency in embedded
  computing. We propose to abstract data accesses through an
  \emph{accessor} class to give control to the programmer on how fine
  grain access is done, such as caching, memory burst or remote access
  in heterogeneous computing.
\end{abstract}


\tableofcontents

\section{Motivation}
\label{sec:motivation}

Demand for high-performance and power efficiency makes architectural
considerations more and more important when programming, specially with
the generalization of distributed computing and heterogeneous
computing involving accelerators, DSP, GPU, FPGA, network
accelerators, etc.

Unfortunately, as for a sequential program running on a CPU, there is
no performance portability when it is about reaching the maximum
performance and power efficiency on a given architecture. Some
execution parameters may have to be tweaked and/or the architecture of the
software has to be deeply changed accordingly. Since there are more
parameters under control in an heterogeneous platform compared to a
CPU, the exploration space is quite wider. Dealing with
this in an automatic way is an intractable issue in the general case but
at least we should have some ways to express some of these details at
the C++ level to reach maximum performance and power efficiency.

For example currently there is no way to specify how the data are
accessed and if we consider that now most of the energy consumption is
spent in data transfer, specially with external memory, this is
something to address.

Keeping data on a first-level cache in CPU is crucial and it is
important to express which data will benefit or not from being in the
cache. Since cache memories are very small and expensive, specifying
that some data do not take advantage of the cache leaves more room for
data in the critical path.

In the following we develop the concept of \emph{accessor} represented
as a plain C++ class to express how data are accessed in a C++
program.

An accessor is a proxy object that behaves like the object it
represents but with some ways to change the behaviour when read or
written.

Most of the behaviour could be done by language extensions or
\lstinline|#pragma|, but the advantage of having it as a class is that
it can often be implemented in user-mode C++ for simplicity,
portability or debug, and also implemented by a compiler in a
target-specific optimized way on some architectures.

Having a plain object to control accesses provides handy RAII
framework to hide actions in the accessor constructor and destructor,
such as setting up the communication framework or switching on and off
the power of the system that gives access to the object.

Having access properties encoded in the type itself allows propagation
though generic templated function calls and allows code specialization
with metaprogramming according to some access properties.


\section{Related work}
\label{sec:related-work}

In current C++ standard and proposals, some architectural aspects can
already or will be addressed:
\begin{description}
\item[\texttt{thread}] can be used to execute some code in parallel
  on multiple execution units;
\item[\texttt{allocator}] controls the way allocation happens and how
  pointers behave, and thus hide some hardware detail for data access;
\item[constructors and destructors] can hide some architectural details
  and semantics;
\item[operator overloading] is useful to hide some hardware
  operations;
\item[\texttt{auto} operator overloading] would make cleaner implementation of
  proxy to some hardware details and cleaning up expression templates;
\item[fixed-point] type proposals are useful to have better
  performance on DSP and FPGA;
\item[the concept of view] has some similarities but is more focused
  on some kind of objects, such as \lstinline|array_view| for arrays,
  \lstinline|string_view| for strings, or \lstinline|span| to view a
  sequence as a range;
\item[SYCL] is a proposal to execute some functors on some
  accelerators with possibly different address spaces;
\item[ISO/IEC TR 18037] in the C world, ``Information Technology ---
  Programming languages -- C -- Extensions to support embedded
  processors'' (ISO/IEC JTC1 SC22 WG14 N1169, 2006-04-04
  \url{http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1169.pdf})
  introduces concepts such as the \emph{named address spaces} to
  represent special kinds of memories, that went recycled into CUDA
  and OpenCL address spaces, or named registers and special I/O.
\end{description}

The concept of accessor discussed here is more focused on the action
of reading or writing than on the kind of object.


\section{Accessor}
\label{sec:accessor}

\subsection{Non unified memory}
\label{sec:non-unified-memory}

The current C++ memory model assumes more or less that the memory
address space is uniform. Unfortunately, for HPC class machines from
the Top 500 or for embedded systems, this simple addressing scheme
does not hold and there are for example some private memory attached
to each processor or device that cannot be addressed directly by
another processor or device.

The motivation for this \lstinline|accessor| proposal actually comes
from OpenCL SYCL C++ where some functors are remotely executed but need
to interact with a global memory. This is also the concept behind PGAS
(Partitioned Global Address Space) languages or libraries, such as
Coarray C++ or UPC++, where the memory is physically distributed but
can be remotely accessed with some explicit language or library
support instead of transparent virtual shared memory.

The use of a (SYCL) accessor can be seen on this SYCL C++ example:
\begin{lstlisting}
// Create a 1D buffer of N double
cl::sycl::buffer<double, 1> b { N };
// [...]
// Launch on default accelerator:
cl::sycl::queue {}.submit([&](handler &cgh) {
  /* Get an accessor to write the data remotely from inside lambda
     which is off-loaded to the accelerator */
  auto acc = b.get_access<access::write>(cgh);
  // A DIY parallel equivalent of std::iota as a kernel named "init"
  cgh.parallel_for<class init>(N, [=] (auto index) {
                                acc[index] = index;
                               });
  });
\end{lstlisting}

could be generalized in a framework returning a remote accessor to
allow remote access as:
\begin{lstlisting}
std::array<double, N> local;
accessor<remote, write, std::array<double, N>> remote =
  get_some_runtime_remote(local);

std::copy(std::begin(local), std::end(local), std::begin(remote));
\end{lstlisting}

Typical environments usable with this could be SHMEM, Portal4, SYCL,
Coarray C++, RDMA, iWARP, MPI...


\subsection{Read/write qualifiers}
\label{sec:readwrite-qualifiers}

In C++ there is the \lstinline|const| qualifier to specify read-only
but there is no way to specify other access modes that normally do not
change the semantics but are useful to increase performance or lower
power consumption.

Here is a list of accessor types:
\begin{description}
\item[\texttt{write}] to access to a write-only data. This avoids for
  example to load or prefetch the cache from memory before writing;
\item[\texttt{read}] to prevent writing back data;
\item[\texttt{read\_write}] normal access by symmetry;
\item[\texttt{discard\_read}] to read data if they are written first
  and do not read the initial value at accessor creation. A typical
  use case is a data locally generated that can be read back locally;
\item[\texttt{discard\_write}] to write data to be locally read but
  won't be written back at accessor destruction;
\item[\texttt{noaccess}] by symmetry, typically to detect
  inappropriate behaviours in a program.
\end{description}


\subsection{Non temporal access}
\label{sec:non-temporal-access}

A \lstinline|non_temporal| accessor allows to access data that won't
be accessed again and typically will not for example use a cache. This
diminish cache transactions and leave the cache for some more useful
usage.

For example when generating a huge amount of data to an array, everything else
would be evicted from the cache without any chance to read the array
back from the cache anyway.

A use case:
\begin{lstlisting}
// An array of 1 TB
double a[2<<37];
auto ac = make_accessor<non_temporal,write>(a);
// Initialize a starting from the end with increasing
// integer starting at 42
std::iota(std::par_vec, ac.rbegin(), ac.rend(), 42);
\end{lstlisting}


\subsection{Sequential access}
\label{sec:sequential-access}

In some case the programmer knows that accesses to an array are
strictly sequential but the compiler cannot prove it. By explicitly
specifying it, a compiler can generate vector memory access or do some
parallel loop nest pipelining where the memory access is completely
replaced for example by a hardware FIFO between execution units.

In the program
\begin{lstlisting}
{
  std::accessor<accessor::sequential,
                accessor::discard_read,
                accessor::discard_write> a { some_array };
  for (int i; i = 0; i != N; ++i)
    a[i] = i;
  for (int i; i = 0; i != N; ++i)
    b[i] = a[i]*2;
}
\end{lstlisting}
the compiler could decide to fuse the 2 loops or to generate 2 Kahn's
processes, 1 producer and 1 consumer, with only an efficient hardware
FIFO in between and eluding the memory transfer on \lstinline|a[i]|.


\subsection{Prefetching}
\label{sec:prefetching}

Latency is often a performance killer and if we know in advance that
we will read some array elements, we could prefetch it. Note that
prefetching is actually independent from caching, so it can be
combined with non temporal access.

\begin{lstlisting}
int a[N];
// Instruct the memory prefetcher to look 16 elements ahead
std::accessor<prefetch<16>> { a_p };
std::fill(std::begin(a_p), std::end(a_p), 0);
\end{lstlisting}


\subsection{Burst mode}
\label{sec:burst-mode}

Most of the memory interfaces work better when memory transfers are
made with a coarse granularity. It can be specified with this accessor.

Note that since burst mode uses bulk transfer mode, it is not
interesting for example when transferring small data randomly
placed. In this case a burst-size of 1 with a non temporal accessor
can be used.

\begin{lstlisting}
int a[N*20];
// Instruct the memory prefetcher to use a burst mode of 20 elements
std::accessor<burst<20>> a_p { a };

// To generate random integer between 0 and N - 1
std::default_random_engine r;
std::uniform_int_distribution<int> d { 0, N - 1 };
for (int i = 0; i != N; ++i) {
  // Randomly write blocks of 20 elements
  p = std::begin(a_p) + 20*d(r);
  std::fill(p, p + 20, 0);
}
\end{lstlisting}


\subsection{DMA}
\label{sec:dma}

To take advantage from DMA to transfer data, the transfer can be
encoded as a DMA operation with a DMA accessor.

TODO.


\subsection{Memory protection}
\label{sec:memory-protection}

Out-of-bound memory access is evil and root of many security
issues. Systematic bound checking is costly but some architectures
provides this for free so it is interesting to express with a specific
accessor:
\begin{lstlisting}
char a[N];
// Use a bound-checker accessor to protect from deprecated insecure
// function
std::accessor<bound_check> a_s { a, 20 };
// Use a dangerous function but throw in case of out-of-bound access
gets(a_s);
}
\end{lstlisting}

TODO \textbf{Difficult to have this working}


\subsection{Bus type}
\label{sec:bus-type}

Some systems allow different types of buses an a variable may be
addressed through these different buses with an accessor specifying a
bus identifier. The concept is standard but the bus identifiers,
besides the default one, are implementation specific:
\begin{lstlisting}
char a;
float b;
std::accessor<bus<axi4>> a_a { a };
std::accessor<bus<axi4>> b_a { b };
std::accessor<bus<main> a_m { a };
std::accessor<bus<main> b_m { b };
// Use different buses in parallel to improve bandwidth
auto sum = a_a + b_m;
auto prod = a_m + b_a;
\end{lstlisting}

The synchronization constraints between the various buses are
implementation dependent.


\subsection{Access width}
\label{sec:access-width}

Embedded systems allow to specify the size of the data-packets
transferred on a bus. This can be specified with:
\begin{lstlisting}
double d;
// Transfer 8-bit at a time
std::accessor<bit_width<8>> d_b { d };
auto a = d_b;
\end{lstlisting}


\subsection{Address mode}
\label{sec:address-mode}

Some architectures allow different addressing modes with different
trade-off, such as PC-relative, based on a base pointer, near to some
page, etc. To compile efficiently with this mode a specific accessor
is provided.

\textbf{Difficult to have this working}


\subsection{Translation}
\label{sec:translation}

In embedded systems, it is common to have some level of shared memory
but mapped physically at different addresses. If there is no virtual
memory in use in some part of a system, the address in the different
point-of-views appear as translated by an offset.
\begin{lstlisting}
unsigned char frame_buffer[N];
size_t offset = &display - frame_buffer;
// The screen memory on the display controller
std::accessor<translate> b { frame_buffer, offset };
\end{lstlisting}


\subsection{Modulo addressing}
\label{sec:modulo-addressing}

Implementing some circular buffers may require some kind of modulo
addressing and some processors have this addressing mode. Since it is
impossible to detect automatically this feature in the compiler in the
general case, it should be expressed with an accessor:
\begin{lstlisting}
unsigned char buffer[N];
// b is a kind of infinite array, but with only buffer storage repeated
std::accessor<modulo> b { buffer };
\end{lstlisting}


\subsection{Bit setting}
\label{sec:bit-setting}

Some architecture encode in the address bus some semantics which is
not used as the part of the address itself, such as supervisor mode,
non executable mode, etc.

A bit-setting accessor allows to change the address bit accordingly
during read or write operations.


\subsection{Transactional memory}
\label{sec:transactional-memory}

A transactional-memory accessor start a transaction at the accessor
creation up to its destruction, with some transaction behaviour for
the threads using this accessor. In case of write data-race, only one
of the conflicting threads are not rolled back up to the construction
of the accessor.


\subsection{Generic proxy}
\label{sec:generic-proxy}

A proxy accessor delegates all the read and write operations to some
user-provided functors.

It is useful for example for:
\begin{itemize}
\item virtualizing some non existant memory or hardware;
\item implementing transactional memory in user mode;
\item testing with some non existing software part by interacting with
  a mock-up hidden behind an accessor;
\item override the memory operation to do fault injection for
  fault-tolerance evaluation;
\item security testing with fuzzing of inputs.
\end{itemize}


\section{Implicit accessor}
\label{sec:implicit-accessor}

Having to use explicit \texttt{accessor} objects may be painfully
intrusive and it would be nice to have something lighter. Of course,
since omnipotent abstract interpretation of a program is impossible,
some kind of program transformation is required by the programmer to
express properties of memory access.

We can use language extensions, \lstinline|#pragma| or generalized
attributes. Language extensions are bad for portability and
acceptance. \lstinline|#pragma| do not compose well with
meta-programming. So we focus here on decorating objects with
accessors.

\begin{lstlisting}
// An array of 1 TB
double a[2<<37] [[std::accessor<non_temporal,sequential>]];

// An implicit accessor is wrapped around all uses of a
std::iota(a.begin(), a.end(), 0);
\end{lstlisting}

But also on any scope, such as class, block, namespace... as for
example to add a behaviour of a transactional memory on all a class:
\begin{lstlisting}
template <typename T>
class message_queue [[std::accessor<transaction>]] {
  T read() {...}

  void write(T &&t) {...}
}
\end{lstlisting}


\section{Implementation}
\label{sec:implementation}

The implementation basics for the proxy objects are:
\begin{itemize}
\item for fundamental types, have an implicit conversion operator to
  the reference to the fundamental types so the accessor can behave
  like the fundamental type;
\item for object types, the proxy would publicly inherit from the type to
  forward all member access to it.
\end{itemize}


\section{Issues}
\label{sec:issues}

Having some objects appearing at other addresses may put some
restriction on the type (such as ``trivially copyable'', ``standard
layout''...).


\section{Acknowledgements}
\label{sec:acknowledgements}

We want to thank all the people from the Khronos OpenCL SYCL committee
for the fruitful discussions leading to this generalization of the
concept of accessor.


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
