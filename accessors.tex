\documentclass[a4paper]{article}


\usepackage{a4wide}
\usepackage{listings}
\lstset{language=C++,basicstyle=\small\ttfamily}

\title{C++ draft proposal\\
  ---\\
  Accessors}

\author{Ronan Keryell \texttt{<ronan.keryell@xilinx.com>}\\
  xyz \texttt{<xyz@codeplay.com>}}

\begin{document}

\maketitle

\section{Introduction}
\label{sec:introduction}

Demand for high-performance and power efficiency makes architectural
considerations more an more important when programming, specially with
the generalization of distributed computing and heterogeneous
computing involving accelerators, DSP, GPU, FPGA, etc.

Unfortunately, as for a sequential program running on a CPU, there is
no performance portability when it is about reaching the maximum
performance and power efficiency on a given architecture. Some
execution parameters may have to be tweaked or the architecture of the
software has to be deeply changed accordingly. Since there are more
parameters under control in an heterogeneous platform compared to a
CPU, the exploration space is quite wider. Dealing with
this an automatic way is an intractable issue in the general case but
at least we should have some way to express some of these details at
the C++ level to reach maximum performance and power efficiency.

In current C++ standard and proposals, some architectural aspects can
already or will be addressed:
\begin{description}
\item[\texttt{thread}] can be used to execute some code in parallel
  on multiple execution units;
\item[\texttt{allocator}] controls the way allocation happens and how
  pointers behave, and thus hide some hardware detail for data access;
\item[constructors and destructors] can hide some architectural details
  and semantics;
\item[operator overloading] is useful to hide some hardware
  operations;
\item[\texttt{auto} operator overloading] would make cleaner implementation of
  proxy to some hardware details and cleaning up expression templates;
\item[fixed-point] type proposals are useful to have better
  performance on DSP and FPGA;
\item[SYCL] is a proposal to execute some functors on some
  accelerators with possibly different address spaces.
\end{description}

But currently there is no way to specify how the data are accessed and
if we consider that now most of the energy consumption is spent in
data transfer, specially with external memory, this is something to
address.

For example keeping data on a first-level cache in CPU is crucial and
it is important to express which data will benefit or note from being
in the cache. Since cache are very small, specifying that some data
does not take advantage of the cache leaves more room for data in the
critical path.

In the following we develop and extend the concept of \emph{accessor}
to express how data are accessed in a C++ program.


\section{Related work}
\label{sec:related-work}

The concept of view has some similarities but is more focused on some
kind of objects, such as \lstinline|array_view| for arrays,
\lstinline|string_view| for strings, or \lstinline|span| to view a
sequence as a range.

The concept of accessor is more focused on the action of reading or
writing than on the kind of object.


\section{Accessor}
\label{sec:accessor}

An accessor is a proxy object that behaves like the object it
represents but with some ways to change the behaviour when read or
written.

Most of the behaviour could be done by language extensions or
\lstinline|#pragma|, but the advantage of having it as a class is that
it can often be implemented in user-mode C++ for simplicity,
portability or debug, and also implemented by a compiler in a
target-specific optimized way on some architectures.

Having a plain object to control accesses provides handy RAII
framework to hide actions in the accessor constructor and destructor,
such as switching on and off the power of the system that gives access
to the object.


\subsection{Non unified memory}
\label{sec:non-unified-memory}

The current C++ memory model assumes more or less that the memory
address space is uniform. Unfortunately, for HPC class machines from
the Top 500 or for embedded systems, this simple addressing scheme
does not hold and there are for example private memory to each
processor or device that cannot be addressed directly by another
processor or device.

The motivation for this \lstinline|accessor| proposal actually comes
from SYCL where some functors are remotely executed but need to
interact with a global memory. This is also the concept behind PGAS
(Partitioned Global Address Space) languages or libraries, such as
Coarray C++ or UPC++, where the memory is physically distributed but
can be remotely accessed with some explicit language or library
support instead of transparent virtual shared memory.

A SYCL example:
\begin{lstlisting}
// A 1D buffer of N double
cl::sycl::buffer<double, 1> b { N };
// [...]
// Launch on default accelerator:
cl::sycl::queue {}.submit([&](handler &cgh) {
  // Get an accessor to write the data remotely
  auto acc = b.get_access<access::write>(cgh);
  // A parallel equivalent of std::iota as a kernel named "init"
  cgh.parallel_for<class init>(N, [=] (auto index) {
                                acc[index] = index;
                               });
  });
\end{lstlisting}

could be generalized in a framework returning
\begin{lstlisting}
std::array<double, N> local;
accessor<remote, write, std::array<double, N>> remote =
  get_some_runtime_remote(local);

std::copy(std::begin(local), std::end(local), std::begin(remote));
\end{lstlisting}

Typical environment usable with this could be SHMEM, Portal4, SYCL,
Coarray C++, RDMA, iWARP, MPI...


\subsection{Read/write qualifiers}
\label{sec:readwrite-qualifiers}

In C++ there is the \lstinline|const| qualifier to specify read-only
but there is no way to specify other access mode that normally do not
change the semantics but are useful to increase performance.

Here is a list of accessor types:
\begin{description}
\item[\texttt{write}] to access to a write-only data. This avoids for
  example to load or prefetch the cache from memory before writing;
\item[\texttt{read}] to prevent writing back data;
\item[\texttt{read\_write}] normal access by symmetry;
\item[\texttt{discard\_read}] to read data if they are written first
  and do not read the initial value at accessor creation. A typical
  use case is a data locally generated that can be read back locally;
\item[\texttt{discard\_write}] to write data to be locally read but
  won't be written back at accessor destruction;
\item[\texttt{noaccess}] by symmetry, typically to detect
  inappropriate behaviours in a program.
\end{description}


\subsection{Non temporal access}
\label{sec:non-temporal-access}

A \lstinline|non_temporal| accessor allows to access data that won't
be accessed again and typically will not for example use a cache. This
diminish cache transactions and leave the cache for some more useful
usage.

For example when generating a huge amount of data to an array, everything else
would be evicted from the cache without any chance to read the array
back from the cache anyway.

A use case:
\begin{lstlisting}
// An array of 1 TB
double a[2<<37];
auto ac = make_accessor<non_temporal,write>(a);
// Initialize a starting from the end with increasing
// integer starting at 42
std::iota(std::par_vec, ac.rbegin(), ac.rend(), 42);
\end{lstlisting}


\subsection{Sequential access}
\label{sec:sequential-access}

In some case the programmer knows that accesses to an array are
strictly sequential but the compiler cannot prove it. By explicitly
specifying it, a compiler can generate vector memory access or do some
parallel loop nest pipelining where the memory access is completely
replaced for example by a hardware FIFO between execution units.

In the program
\begin{lstlisting}
{
  std::accessor<accessor::sequential,
                accessor::discard_read,
                accessor::discard_write> a { some_array };
  for (int i; i = 0; i != N; ++i)
    a[i] = i;
  for (int i; i = 0; i != N; ++i)
    b[i] = a[i]*2;
}
\end{lstlisting}
the compiler could decide to fuse the loop or to generate 2 Kahn's
processes, 1 producer and 1 consumer, with only an efficient hardware
FIFO in between and eluding the memory transfer on \lstinline|a[i]|.


\subsection{Prefetching}
\label{sec:prefetching}

Latency is a performance killer and if we know in advance we need
something, we could prefetch it. Note that prefetching is actually
independent from caching, so it can combine with non temporal access.


\subsection{Burst mode}
\label{sec:burst-mode}

\subsection{DMA}
\label{sec:dma}

\subsection{Memory protection}
\label{sec:memory-protection}

\subsection{Bus type}
\label{sec:bus-type}

\subsection{Access width}
\label{sec:access-width}

\subsection{Address mode}
\label{sec:address-mode}

PC-relative, far, near, based, indexed

\subsection{Translation}
\label{sec:translation}

In embedded systems, it is common to have some level of shared memory
but mapped physically at different addresses. If there is no virtual
memory in use in some part of a system, the address in the different
point-of-views appear as translated by an offset.
\begin{lstlisting}
unsigned char frame_buffer[N];
// The screen memory on the display controller
std::accessor<translate> b { buffer, offset };
\end{lstlisting}


\subsection{Modulo addressing}
\label{sec:modulo-addressing}

Implementing some circular buffers may require some kind of modulo
addressing and some processors have this addressing mode. Since it is
impossible to detect automatically this feature in the compiler in the
general way, it should be expressed with an accessor:
\begin{lstlisting}
unsigned char buffer[N];
// b is a kind of infinite array, but with only buffer storage repeated
std::accessor<modulo> b { buffer };
\end{lstlisting}


\subsection{Bit setting}
\label{sec:bit-setting}


\subsection{Transactional memory}
\label{sec:transactional-memory}


\subsection{Generic proxy}
\label{sec:generic-proxy}

implementing transactional memory in user mode

mock-up

fault injection

fuzzing


\section{Implicit accessor}
\label{sec:implicit-accessor}

Having to use explicit \texttt{accessor} objects may be painfully
intrusive and it would be nice to have something lighter. Of course,
since omnipotent abstract interpretation of a program is impossible,
some kind of program transformation is required by the programmer to
express properties of memory access.

We can use language extensions, \lstinline|#pragma| or generalized
attributes. Language extensions are bad for portability and
acceptance. \lstinline|#pragma| do not compose well with
meta-programming. So we focus here on to decorate objects with
accessors.

\begin{lstlisting}
// An array of 1 TB
double a[2<<37] [[std::accessor<non_temporal,sequential>]];

// An implicit accessor is wrapped around all uses of a
std::iota(a.begin(), a.end(), 0);
\end{lstlisting}

But also on any scope, such as class, block, namespace... as for
example to add a behaviour of a transactional memory on all a class:
\begin{lstlisting}
template <typename T>
class message_queue [[std::accessor<transaction>]] {
  T read() {...}

  void write(T &&t) {...}
}
\end{lstlisting}


\section{Implementation}
\label{sec:implementation}

The implementation basics for the proxy objects are:
\begin{itemize}
\item for fundamental types, have an implicit conversion operator to
  the reference to the fundamental types so the accessor can behave
  like the fundamental type;
\item for object types, the proxy would publicly inherit from the type to
  forward all member access to it.
\end{itemize}


\section{Issues}
\label{sec:issues}

Having some objects appearing at other addresses may put some
restriction on the type (such as ``trivially copyable'', ``standard
layout''...).


\section{Acknowledgements}
\label{sec:acknowledgements}

We want to thank all the people from the Khronos OpenCL SYCL committee
for the fruitful discussions leading to this generalization of the
concept of accessor.


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
